Based on the provided context, the criteria used to split the data for deep learning model training in this study are as follows: - **Number of Training Steps and Validation Percentage:** The researchers modified the number of training steps and the validation percentage to optimize the balance between computing time and classification efficiency. Due to the limited number of images per species (n = 20), they increased the validation parameter to 20%. - **Leave-One-Out Cross Validation:** Because of the small sample size, they used a leave-one-out cross validation technique to evaluate model performance in some of the classification challenges. This means that for each iteration, one sample is used as the test set while the remaining samples are used for training. - **Separate Test Dataset:** In Challenge 2, after training the model on a reference library, they tested it on a separate dataset consisting of species not present in the training set to evaluate the model's ability to generalize to new, unseen species. - **Species Pool Subsets:** In Challenge 4, they created subsets of species based on their distribution on different Philippine islands, resulting in smaller, localized species pools for separate classification tasks. In summary, the data splitting criteria included adjusting the validation percentage, using leave-one-out cross validation due to small sample sizes, and creating separate test datasets and species pool subsets for specific classification challenges. 